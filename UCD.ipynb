{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a49298-2750-42c0-9c72-10d5c06ae041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_community\n",
    "# !pip install --upgrade langchain \n",
    "# !pip install langchain-cohere\n",
    "# !pip install --upgrade langchain langchain-openai langchain-cohere langchain_community\n",
    "# !pip install -U langchain-ollama\n",
    "# !pip install -U langchain-opena\n",
    "# !pip install pypdf\n",
    "# !pip install --upgrade langchain langchain-ollama langchain-cohere chromadb pypdf\n",
    "# !pip install streamlit\n",
    "# !pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c3e83c-520b-40cd-ac92-8d0927ff210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "import base64\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94eb7ace-6c08-43e0-a5c6-4857968f5e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# Paid\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) \n",
    "embeddings = OpenAIEmbeddings() #Text embedding small (default)\n",
    "\n",
    "# # Free\n",
    "# llm = OllamaLLM(model=\"llama13\")\n",
    "# embeddings = CohereEmbeddings()\n",
    "# embeddings = CohereEmbeddings(\n",
    "#     cohere_api_key=\"\",\n",
    "#     model=\"embed-english-v2.0\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fbfb68a-cb8b-4d87-89e5-b76b8efd5cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting UCD_QA_Buddy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile UCD_QA_Buddy.py\n",
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "import base64\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# ---- STYLING AND HTML FOR THE CHAT ----\n",
    "st.set_page_config(page_title=\"UCD Q/A buddy\", page_icon=\":robot_face:\")\n",
    "\n",
    "CSS = \"\"\"\n",
    "<style>\n",
    ".chat-message {\n",
    "    padding: 1.5rem; \n",
    "    border-radius: 0.5rem; \n",
    "    margin-bottom: 1rem; \n",
    "    display: flex;\n",
    "}\n",
    ".chat-message.user {\n",
    "    background-color: #2b313e;\n",
    "}\n",
    ".chat-message.bot {\n",
    "    background-color: #475063;\n",
    "}\n",
    ".chat-message .avatar {\n",
    "  width: 20%;\n",
    "  text-align: center;\n",
    "}\n",
    ".chat-message .avatar img {\n",
    "  max-width: 60px;\n",
    "  max-height: 60px;\n",
    "  border-radius: 50%;\n",
    "  object-fit: cover;\n",
    "}\n",
    ".chat-message .message {\n",
    "  width: 80%;\n",
    "  padding: 0 1.5rem;\n",
    "  color: #fff;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "logo_path = r\"C:\\Users\\Sagar\\Tech_Consulting_GenAI\\logo.jpg\"\n",
    "\n",
    "with open(logo_path, \"rb\") as f:\n",
    "    logo_data = f.read()\n",
    "\n",
    "# Base64-encode the binary data\n",
    "encoded_logo = base64.b64encode(logo_data).decode(\"utf-8\")\n",
    "\n",
    "bot_template = f\"\"\"\n",
    "<div class=\"chat-message bot\">\n",
    "    <div class=\"avatar\">\n",
    "        <!-- Embed as data URI -->\n",
    "        <img src=\"data:image/jpeg;base64,{encoded_logo}\" />\n",
    "    </div>\n",
    "    <div class=\"message\">{{{{MSG}}}}</div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "user_template = f\"\"\"\n",
    "<div class=\"chat-message user\">\n",
    "    <div class=\"avatar\">\n",
    "        <img src=\"data:image/jpeg;base64,{encoded_logo}\" />\n",
    "    </div>\n",
    "    <div class=\"message\">{{{{MSG}}}}</div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "st.markdown(CSS, unsafe_allow_html=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Helper Functions\n",
    "# -----------------------------\n",
    "def add_logo(logo_file, width=80, height=40):\n",
    "    \"\"\"Return a resized PIL image of the provided logo file path.\"\"\"\n",
    "    img = Image.open(logo_file)\n",
    "    return img.resize((width, height))\n",
    "\n",
    "def load_pdfs_as_documents(uploaded_files):\n",
    "    all_docs = []\n",
    "    for uploaded_file in uploaded_files:\n",
    "        # Write in-memory file to a temporary PDF file\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".pdf\", delete=False) as tmp:\n",
    "            file_bytes = uploaded_file.read()\n",
    "            tmp.write(file_bytes)\n",
    "            tmp.flush()  # make sure all data is written\n",
    "\n",
    "            # Now pass the temp file path to PyPDFLoader\n",
    "            loader = PyPDFLoader(tmp.name)\n",
    "            docs = loader.load()\n",
    "\n",
    "        all_docs.extend(docs)\n",
    "    return all_docs\n",
    "\n",
    "def split_into_chunks(documents, chunk_size=1000, chunk_overlap=100):\n",
    "    \"\"\"Split documents into smaller chunks for better retrieval.\"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return splitter.split_documents(documents)\n",
    "\n",
    "# -----------------------------\n",
    "# Main App\n",
    "# -----------------------------\n",
    "def main():\n",
    "    # Title / Header\n",
    "    st.title(\"UCD Q/A buddy\")\n",
    "\n",
    "    # Sidebar for PDF Upload\n",
    "    st.sidebar.header(\"Upload your PDF(s) below\")\n",
    "    uploaded_pdfs = st.sidebar.file_uploader(\n",
    "        \"Select one or more PDF files\",\n",
    "        type=[\"pdf\"],\n",
    "        accept_multiple_files=True\n",
    "    )\n",
    "\n",
    "    if \"chat_history\" not in st.session_state:\n",
    "        st.session_state[\"chat_history\"] = []\n",
    "\n",
    "    # Once user clicks \"Process\"...\n",
    "    if st.sidebar.button(\"Process\"):\n",
    "        if uploaded_pdfs:\n",
    "            with st.spinner(\"Loading and splitting PDFs...\"):\n",
    "                # 1) Load the uploaded PDFs as documents\n",
    "                docs = load_pdfs_as_documents(uploaded_pdfs)\n",
    "\n",
    "                # 2) Split into chunks\n",
    "                split_docs = split_into_chunks(docs, chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "                # 3) Create in-memory Chroma vectorstore\n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                vectorstore = Chroma.from_documents(split_docs, embedding=embeddings)\n",
    "\n",
    "                # 4) Create a RetrievalQA chain\n",
    "                llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "                st.session_state[\"qa_chain\"] = RetrievalQA.from_chain_type(\n",
    "                    llm=llm,\n",
    "                    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "                )\n",
    "                st.success(\"PDFs processed! You can now ask questions below.\")\n",
    "        else:\n",
    "            st.warning(\"Please upload at least one PDF before clicking 'Process'.\")\n",
    "\n",
    "    # User's question input\n",
    "    user_question = st.text_input(\"Ask a question about your documents:\")\n",
    "    if user_question and \"qa_chain\" in st.session_state:\n",
    "        response = st.session_state[\"qa_chain\"].run(user_question)\n",
    "        # Update chat history\n",
    "        st.session_state[\"chat_history\"].append((\"user\", user_question))\n",
    "        st.session_state[\"chat_history\"].append((\"bot\", response))\n",
    "\n",
    "    # Display Chat History\n",
    "    for role, msg in st.session_state[\"chat_history\"]:\n",
    "        if role == \"user\":\n",
    "            st.markdown(user_template.replace(\"{{MSG}}\", msg), unsafe_allow_html=True)\n",
    "        else:  # bot\n",
    "            st.markdown(bot_template.replace(\"{{MSG}}\", msg), unsafe_allow_html=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "774aa3b2-0623-4b90-a60b-dce1f9423ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run UCD_QA_Buddy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e414b1a9-e5f0-414b-bf96-e73a6282059e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
